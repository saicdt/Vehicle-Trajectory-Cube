#!/usr/bin/env python

import sys,dateutil.parser,datetime,argparse,re,subprocess,os,json,socket

import cStringIO as StringIO
import pandas as pd
import numpy as np

class NanocubeInput:
    def __init__(self, args):
        self.field=[]
        self.valname={}
        self.catbins={}
        
        self.minlatlon={}
        self.maxlatlon={}

        #esc char fixes
        self.sep = args.sep
        self.sep = self.sep.replace('\\t','\t')
        self.sep = self.sep.replace('\\n','\n')
        self.sep = self.sep.replace('\\r','\r')

        self.name = args.name
        if self.name == '':
            self.name=args.InputFile[0]

        if self.name == '-':
            self.name= 'Nanocube'


        self.timebinsize=self.parseTimeBin(args.timebinsize)

        self.spname=args.spname.split(self.sep)

        self.latcol=args.latcol.split(self.sep)
        self.loncol=args.loncol.split(self.sep)
        
        self.xcol=args.xcol
        self.ycol=args.ycol
        if self.xcol is not None and self.ycol is not None:
            self.xcol=args.xcol.split(self.sep)
            self.ycol=args.ycol.split(self.sep)
            self.latcol=self.ycol
            self.loncol=self.xcol
                    
        self.timebytes = args.timebytes
        self.countbytes = args.countbytes
        self.catbytes = args.catbytes
        
        try:
            self.catcol = args.catcol.split(self.sep)
        except:
            self.catcol = []

        try:
            self.timecol = args.timecol.split(self.sep)
        except:
            self.timecol = []

        try:            
            self.ncheader = open(args.ncheader,'r').readlines()
            
            #read the header
            ncheader = self.readNCHeader(self.ncheader)
            self.valname = ncheader['valname']
            self.countbytes = ncheader['countb']
            self.timebytes = ncheader['timeb']
            self.catbytes = ncheader['catb']
            
            #make this header printable
            self.ncheader = "".join(self.ncheader).strip()+"\n\n"
        except:
            self.ncheader = None
            
        try:
            self.offset = dateutil.parser.parse(args.offset)
        except:
            self.offset = None


        try:
            self.header=args.header.split(self.sep)
        except:
            self.header=None

        self.countcol = args.countcol


        self.datefmt=args.datefmt
        self.levels = args.levels
        self.chunksize = args.chunksize
        self.tz = args.tz
        
        for s in self.spname:
            self.minlatlon[s] = [float("inf"),float("inf")]
            self.maxlatlon[s] = [float("-inf"),float("-inf")]

        try:
            ppcat = args.preprocesscat.split(self.sep)
            self.preprocessCat(args.InputFile,ppcat,self.chunksize)
        except:
            pass
            
        try:
            bincat = args.bincat.split(self.sep)
            nbins = args.nbins
            self.binCat(bincat,nbins)
        except:
            pass
        
        #Read the csv file
        self.readcsv(args.InputFile,self.chunksize)

    def preprocessCat(self,files,cols,csize=20000,nbins=None):
        for f in files:
            comp = None
            if f.split('.')[-1] == 'gz':
                comp = 'gzip'

            if f == '-': ### cannot preprocess
                return

            coi = cols
            reader = pd.read_csv(f,chunksize=csize,
                                 error_bad_lines=False,sep=self.sep,
                                 compression=comp,names=self.header,
                                 usecols=coi,dtype=str)

            datarange = {}
            for i,data in enumerate(reader):
                data = data[coi].dropna()
                self.processCat(data)
                
    def binCat(self,cols,nbins=10):
        # compute the bins
        for c in cols:
            f = map(lambda x: float(x),self.valname[c].keys())
            s = pd.Series(f)
            self.catbins[c]=s.quantile(np.linspace(0,1.0,nbins+1)).tolist()

            self.valname[c]={}
            for i,v in enumerate(self.catbins[c]):
                if i==0:
                    continue
                k = '%5.3f-%5.3f'%(self.catbins[c][i-1], v)
                self.valname[c][k] = i-1;
                

    def readcsv(self,files,csize=20000):
        coi = self.timecol+self.catcol+self.latcol+self.loncol
        if self.countcol is not None:
            coi += [self.countcol]
        start = True

        for f in files:
            comp = None
            if f.split('.')[-1] == 'gz':
                comp = 'gzip'

            if f == '-':
                f=sys.stdin

            reader = pd.read_csv(f,chunksize=csize,
                                 error_bad_lines=False,sep=self.sep,
                                 compression=comp,names=self.header,
                                 usecols=coi,dtype=str)

            for i,data in enumerate(reader):
                data = data[coi].dropna()
                data = self.processData(data)

                if start:
                    if self.ncheader is None:
                        self.ncheader = self.createHeader(data)
                    sys.stdout.write(self.ncheader)
                    start = False

                self.writeRawData(data)

    def readNCHeader(self,header):
        valname = {}
        cat = 0
        time = 0
        count = 0
        for line in header:
            try:
                s = line.strip().split(':')
                if s[0]=='field':
                    ss = s[1].strip().split()
                    catm = re.match('nc_dim_cat_([0-9])', ss[1])
                    timem = re.match('nc_dim_time_([0-9])', ss[1])
                    countm = re.match('nc_var_uint_([0-9])', ss[1])
                    
                    if catm:                        
                        cat = int(catm.group(1))
                    if timem:
                        time = int(timem.group(1))
                    if countm:
                        count = int(countm.group(1))
                            
                                        
                if s[0]=='valname':
                    ss = s[1].strip().split()
                    attr = ss[0].replace(' ','_')
                    val = int(ss[1])
                    name = ' '.join(ss[2:])
                    if attr not in valname:
                        valname[attr] = {}
                    valname[attr][name]=val

            except:
                continue

        return {'countb':count, 'timeb': time, 'catb':cat, 'valname': valname}

    def processData(self, data):
        if self.countcol is None:
            self.countcol = 'count'

        if self.countcol not in data.columns: #add count
            data[self.countcol]=1

        #get NaN's for errors
        data[self.countcol] = pd.to_numeric(data[self.countcol],errors='coerce');
        
        #drop bad data
        data = data.dropna()

        #process data
        if self.xcol is None and self.ycol is None:
            data = self.processLatLon(data)
        data = self.processCat(data)


        if len(self.timecol) < 1: #use default time
            self.offset = datetime.datetime.now()
            self.timecol = ['defaulttime']

        if ['defaulttime'] == self.timecol:
            data['defaulttime'] = 0 # add default time
        else:
            data = self.processDate(data) # process real time
        return data

    def writeRawData(self,data):
        columns = []
        for i,spname in enumerate(self.spname):
            columns += [self.loncol[i],self.latcol[i]]
            data[self.loncol[i]] = data[self.loncol[i]].astype('<u4');
            data[self.latcol[i]] = data[self.latcol[i]].astype('<u4');

        for i,c in enumerate(self.catcol):
            columns += [c]
            if self.catbytes == 1:
                data[c] = np.minimum(data[c],2**8-2)
                data[c] = data[c].astype('<u1');                
            elif self.catbytes == 2:
                data[c] = np.minimum(data[c],2**16-2)
                data[c] = data[c].astype('<u2');
            elif self.catbytes == 4:
                data[c] = np.minimum(data[c],2**32-2)
                data[c] = data[c].astype('<u4');
            else:
                raise Exception("invalid byte size")

        for i,d in enumerate(self.timecol):
            columns += [d]            
            data[d] = data[d].astype('<u%d'%(self.timebytes));

        columns += [self.countcol]

        data[self.countcol] = data[self.countcol].astype('<u%d'%(self.countbytes))

        data = data[columns] #permute

        rec = data.to_records(index=False)
        rec.tofile(sys.stdout)
        
    def processLatLon(self,data):
        for i,spname in enumerate(self.spname):
            lat = self.latcol[i]
            lon = self.loncol[i]
            lvl = self.levels
            data[lon] = pd.to_numeric(data[lon],errors='coerce')
            data[lat] = pd.to_numeric(data[lat],errors='coerce')
            data = data.dropna()

            data = data[data[lon] > -180]
            data = data[data[lon] < 180]
            data = data[data[lat] > -85.0511]
            data = data[data[lat] < 85.0511]

            #update min max latlon
            self.minlatlon[spname][0] = min(data[lat].min(),
                                            self.minlatlon[spname][0])
            self.minlatlon[spname][1] = min(data[lon].min(),
                                            self.minlatlon[spname][1])
            self.maxlatlon[spname][0] = max(data[lat].max(),
                                            self.maxlatlon[spname][0])
            self.maxlatlon[spname][1] = max(data[lon].max(),
                                            self.maxlatlon[spname][1])

            data[lon] = self.lonToTileX(data[lon],lvl)
            data[lat] = self.latToTileY(data[lat],lvl)
        return data.dropna()

    def processDate(self, data):
        for i,d in enumerate(self.timecol):
            if self.datefmt is None and data[d].dtype == 'int64' :
                data[d] *= 1e9

            if (self.datefmt):
                data[d] = pd.to_datetime(data[d].astype(str),
                                         infer_datetime_format=False,
                                         format=self.datefmt)
            else:
                data[d] = pd.to_datetime(data[d],infer_datetime_format=True)

            #if the strings are crazy coerce will fix it
            didx = pd.to_datetime(data[d],errors='coerce')
            didx = pd.DatetimeIndex(didx).tz_localize(self.tz,ambiguous='NaT')
            didx = didx.tz_convert('UTC').tz_localize(None)
            data[d]=didx
            
        #drop NaT
        data=data.dropna()

        if self.offset is None: #compute offset
            year = data[self.timecol].min().min().year
            month = data[self.timecol].min().min().month
            self.offset = datetime.datetime(year=year,month=month,day=1)
            #,
            #                                tzinfo=pytz.timezone(self.tz))
        
        
        self.offset = pd.to_datetime(self.offset)    
        data = data[data[d] >= self.offset] #Avoid negative time
        for i,d in enumerate(self.timecol):
            data[d] -= self.offset
            data[d] = data[d] / self.timebinsize
        return data.sort_values(by=self.timecol)

    def processCat(self,data):
        for i,c in enumerate(self.catcol):
            #binning
            if c in self.catbins:
                def lessThan(x,quantiles):
                    for i,v in enumerate(quantiles[1:]):
                        if float(x) <= v:
                            return i;
                        
                data[c] = data[c].apply(lambda x :lessThan(x,self.catbins[c]))
                continue #skip the no binning part

            #fix the spaces
            if data.dtypes[c] == object:
                data[c] = data[c].apply(lambda x : str(x).replace(' ','_'))

            #for int type
            if data.dtypes[c] == int:
                data[c] = data[c].apply(lambda x : str(x))
            
            #no binning
            if c not in self.valname:
                self.valname[c] = {}
            labels = np.unique(data[c])

            updateValname = False
            for l in labels:
                if l not in self.valname[c]:
                    updateValname = True
                    newid = len(self.valname[c])
                    self.valname[c][l] = newid

            data[c] = data[c].apply(lambda x : self.valname[c][x])
        return data.dropna()

    def latToTileY(self,lat_deg,zoom):
        lat_deg = np.maximum(-85.0511,lat_deg)
        lat_deg = np.minimum(85.0511,lat_deg)
        lat_rad = lat_deg / 180 * np.pi
        n = 2 ** zoom
        ytile = n*(1-(np.log(np.tan(lat_rad)+1.0/np.cos(lat_rad))/np.pi))/2.0
        return (n-1-ytile) #flip

    def lonToTileX(self,lon_deg,zoom):
        lon_deg = np.maximum(-180,lon_deg)
        lon_deg = np.minimum(180,lon_deg)
        n = 2 ** zoom
        xtile = n*((lon_deg + 180) / 360)
        return xtile

    def parseTimeBin(self,timebinsize):
        match = re.match(r'^(\d+)([smhDWY])$',timebinsize)
        num, unit = match.groups()
        num = int(num)
        td = np.timedelta64(num,unit)
        if unit == 'Y':
            td = np.timedelta64(num*8766,'h')
        return np.timedelta64(td,'s')

    def createHeader(self,data):
        h = ''
        h += 'name: %s\n'%(self.name.replace(' ',"_"))
        h += 'encoding: binary\n'
        for sp in self.spname:
            h += 'metadata: %s__origin degrees_mercator_quadtree%d\n'%(
                sp,self.levels)
            h += 'field: %s nc_dim_quadtree_%d\n'%(sp.replace(' ',"_"),
                                                   self.levels)

        for c in self.catcol:
            h += 'field: %s nc_dim_cat_%d\n'%(c.replace(' ',"_"),
                                              self.catbytes)            
            for k in self.valname[c]:
                h+='valname: %s %d %s\n'%(c.replace(' ',"_"),
                                          self.valname[c][k],k)

        for d in self.timecol:
            h += "metadata: tbin %s_%s_%ds\n"%(self.offset.date(),
                                               self.offset.time(),
                                               self.timebinsize.astype(np.int))
        if self.timebytes == 4:
            h += 'field: %s nc_dim_time_4\n'%(d.replace(' ',"_"))
        else:
            h += 'field: %s nc_dim_time_2\n'%(d.replace(' ',"_"))


        if self.countbytes == 4:
            h += 'field: %s nc_var_uint_4\n\n' %(self.countcol.replace(' ',"_"))
        elif self.countbytes == 8:
            h += 'field: %s nc_var_uint_8\n\n' %(self.countcol.replace(' ',"_"))
        else:
            raise Exception("only supports 4 and 8 bytes for counts")

        return h

def main(argv):
    #parse arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('InputFile',type=str, nargs='+',help="use - for stdin")
    parser.add_argument('--timebinsize',type=str, default='1h')
    parser.add_argument('--timecol', type=str,default=None)
    parser.add_argument('--datefmt', type=str, default=None)
    parser.add_argument('--spname', type=str,default='location')
    parser.add_argument('--levels', type=int, default=25)
    parser.add_argument('--latcol', type=str,default='Latitude')
    parser.add_argument('--loncol', type=str,default='Longitude')
    parser.add_argument('--xcol', type=str,default=None)
    parser.add_argument('--ycol', type=str,default=None)
    parser.add_argument('--catcol', type=str,default=None)
    parser.add_argument('--countcol', type=str, default=None)
    parser.add_argument('--sep', type=str, default=',')
    parser.add_argument('--ncheader', type=str, default=None)
    parser.add_argument('--header', type=str, default=None)
    parser.add_argument('--offset', type=str, default=None)
    parser.add_argument('--chunksize', type=int, default=50000)
    parser.add_argument('--countbytes', type=int, default=4, required=False)
    parser.add_argument('--catbytes', type=int, default=1, required=False)
    parser.add_argument('--timebytes', type=int, default=2, required=False)
    parser.add_argument('--name', type=str, default='')
    parser.add_argument('--tz', type=str, default='UTC')
    parser.add_argument('--preprocesscat', type=str,default=None)
    parser.add_argument('--bincat', type=str,default=None)
    parser.add_argument('--nbins', type=int,default=10)

    args = parser.parse_args()

    ncinput = NanocubeInput(args)


if __name__ == '__main__':
    main(sys.argv)
